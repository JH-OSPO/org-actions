name: "ScanCode License and Citation Scanner"
description: "Scans for licenses and checks for CITATION.cff, DOI, and SWHID."
author: "Your Name"
inputs:
  scan-path:
    description: "Path inside the target repo to scan"
    required: false
    default: "."
  # Removed github-token as we are checking the local file now

runs:
  using: "composite"
  steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.12.3"

    - name: Install ScanCode Toolkit and Dependencies
      shell: bash
      run: |
        echo "Installing dependencies..."
        python -m pip install --upgrade pip
        # ScanCode dependencies
        pip install scancode-toolkit "boolean.py>=4.0" "click==7.1.2"
        # Dependency for reading and parsing CITATION.cff
        pip install pyyaml

    - name: Run ScanCode License Scan
      shell: bash
      run: |
        echo "Running ScanCode license scan on: ${{ inputs.scan-path }}"
        mkdir -p scancode-results
        scancode --license --only-findings --json-pp scancode-results/results.json "${{ inputs.scan-path }}" --ignore "*/venv/*"

    - name: Debug ScanCode Output
      shell: bash
      run: |
        echo "--- ScanCode JSON Output ---"
        cat scancode-results/results.json || echo "No results.json file found."

    - name: Check for Licenses and Citation
      id: check-results
      shell: python
      run: |
        import json
        import os
        import yaml
        import re
        
        # --- CITATION.cff HELPER FUNCTIONS (Simplified for local file check) ---

        def check_citation_yaml(decoded):
            try:
                data = yaml.safe_load(decoded)
            except Exception as e:
                return ['__parse_error__'], [f'YAML parse error: {e}'], None
            if not isinstance(data, dict):
                return ['__not_mapping__'], ['CITATION content did not parse to a mapping (dict)'], data
            
            # Simplified for just checking identifier extraction
            return [], [], data


        def find_swhids_in_data(obj):
            swh_pattern = re.compile(r"swh:1:[a-z]{3}:[0-9a-fA-F:]+", re.IGNORECASE)
            found = set()
            def _scan(o):
                if o is None: return
                if isinstance(o, str):
                    for m in swh_pattern.findall(o): found.add(m)
                elif isinstance(o, dict):
                    for k, v in o.items():
                        if isinstance(k, str) and 'swh' in k.lower() and isinstance(v, str): found.add(v)
                        _scan(v)
                elif isinstance(o, list):
                    for item in o: _scan(item)
                else:
                    try:
                        s = str(o)
                        for m in swh_pattern.findall(s): found.add(m)
                    except Exception: pass
            _scan(obj)
            return list(found)


        def find_dois_in_data(obj):
            doi_pattern = re.compile(r"10\.\d{4,9}/[\w.\-;/()]+", re.IGNORECASE)
            found = set()
            def _scan(o):
                if o is None: return
                if isinstance(o, str):
                    for m in doi_pattern.findall(o): found.add(m)
                elif isinstance(o, dict):
                    for k, v in o.items():
                        if isinstance(k, str) and 'doi' in k.lower() and isinstance(v, str): found.add(v)
                        _scan(v)
                elif isinstance(o, list):
                    for item in o: _scan(item)
                else:
                    try:
                        s = str(o)
                        for m in doi_pattern.findall(s): found.add(m)
                    except Exception: pass
            _scan(obj)
            return list(found)

        def check_identifiers(data):
            issues = []
            identifiers = data.get('identifiers') if isinstance(data, dict) else None
            dois = find_dois_in_data(data)
            swhids = find_swhids_in_data(data)
            
            if identifiers is not None:
                if not isinstance(identifiers, list):
                    issues.append('identifiers must be a list')
                else:
                    for ident in identifiers:
                        if isinstance(ident, dict):
                             id_type = ident.get('type')
                             id_value = ident.get('value')
                             if isinstance(id_type, str) and id_type.lower() == 'doi' and id_value not in dois:
                                 dois.append(id_value)
                             if isinstance(id_type, str) and id_type.lower() in ('swh', 'swhid') and id_value not in swhids:
                                 swhids.append(id_value)
            
            return {'dois': dois, 'swhids': swhids}

        def check_local_citation_file():
            citation_file = 'CITATION.cff'
            if not os.path.exists(citation_file):
                return {"found": False, "comment": "### 📄 CITATION.cff Check\n\n❌ **CITATION.cff file not found.** Consider adding one to make your software citable."}

            try:
                with open(citation_file, 'r', encoding='utf-8') as f:
                    decoded = f.read()
            except Exception as e:
                return {"found": True, "comment": f"### 📄 CITATION.cff Check\n\n⚠️ **Error reading CITATION.cff:** {e}"}

            missing, author_issues, parsed = check_citation_yaml(decoded)
            
            comment = "### 📄 CITATION.cff Check\n\n"
            
            if missing or author_issues:
                # Basic check for parse errors/structure
                comment += "⚠️ **File Structure Issues Found** ⚠️\n\n"
                if missing: comment += f"- **YAML Parse Error:** {', '.join(missing)}\n"
                if author_issues: comment += f"- **Author Issues:** {'; '.join(author_issues)}\n"
            
            filtered = {'dois': [], 'swhids': []}
            if parsed:
                filtered = check_identifiers(parsed)
                citation_title = parsed.get('title', 'N/A')
                comment += f"✅ **File Found and Parsed.**\n- **Title:** `{citation_title}`\n"
            else:
                 comment += "⚠️ **File Found but could not be parsed as YAML.**\n"
            
            if filtered.get('dois'):
                comment += f"- **DOIs Found:** `{', '.join(filtered['dois'])}`\n"
            else:
                comment += "- **DOIs Found:** `None`\n"

            if filtered.get('swhids'):
                comment += f"- **SWHIDs Found:** `{', '.join(filtered['swhids'])}`\n"
            else:
                comment += "- **SWHIDs Found:** `None`\n"

            return {"found": True, "comment": comment}

        # --- License Check Logic ---
        
        output_file = 'scancode-results/results.json'
        license_comment_body = ""
        has_licenses = "false"
        
        if not os.path.exists(output_file):
            license_comment_body = "### ⚠️ ScanCode License Check: FAILED\n\nNo scan results file found for license check."
        else:
            with open(output_file, 'r') as f:
                data = json.load(f)

            if not data.get('files', []):
                license_comment_body = "### ⚠️ ScanCode License Check: NO FILES SCANNED\n\nNo files were found to scan, or the scan failed to produce a valid output."
            else:
                licenses = data.get('license_detections', [])
                if licenses:
                    has_licenses = "true"
                    license_comment_body += "### ✅ ScanCode License Check: SUCCESS\n\nThe following licenses were detected:\n\n"
                    license_comment_body += "| License Expression | Files |\n"
                    license_comment_body += "|---|---|\n"
                    for license_item in licenses:
                        license_expression = license_item['license_expression']
                        file_paths = [match['from_file'] for match in license_item['reference_matches']]
                        license_comment_body += f"| `{license_expression}` | `{', '.join(file_paths)}` |\n"
                else:
                    license_comment_body += "### ⚠️ ScanCode License Check: NO LICENSES DETECTED\n\nNo license information was found in the scanned files."
        
        # Set outputs for license check
        print(f"::set-output name=has_licenses::{has_licenses}")
        print(f"::set-output name=license_comment_body::{license_comment_body}")
        
        # --- Run Citation Check ---
        citation_info = check_local_citation_file()
        print(f"::set-output name=citation_comment_body::{citation_info['comment']}")


    - name: Create or Update Pull Request Comment
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const licenseComment = `${{ steps.check-results.outputs.license_comment_body }}`
          const citationComment = `${{ steps.check-results.outputs.citation_comment_body }}`
          
          const fullCommentBody = `${licenseComment}\n\n---\n\n${citationComment}`
          
          const pull_request_number = context.issue.number;
          const { owner, repo } = context.repo;
          
          // Check if a previous comment from this bot exists
          const { data: comments } = await github.rest.issues.listComments({
            owner,
            repo,
            issue_number: pull_request_number,
          });

          const existingComment = comments.find(
            (comment) => comment.body.includes('### ScanCode License Check') || comment.body.includes('### 📄 CITATION.cff Check')
          );

          if (existingComment) {
            // Update the existing comment
            github.rest.issues.updateComment({
              owner,
              repo,
              comment_id: existingComment.id,
              body: fullCommentBody
            });
          } else {
            // Create a new comment
            github.rest.issues.createComment({
              owner,
              repo,
              issue_number: pull_request_number,
              body: fullCommentBody
            });
          }